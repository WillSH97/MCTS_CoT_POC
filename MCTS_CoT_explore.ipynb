{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8dd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for google colab\n",
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for google colab\n",
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e403983-7020-44c1-998d-0b73703ffe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/hew7/Documents/venvs/RF-demos/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc086d3-e0d8-4949-922b-09af37b5d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18817416-8ee9-433c-b098-4fa157bf2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab208c2a-d096-454c-9187-4a0267b55bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.69s/it]\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "                                           quantization_config=quantization_config, \n",
    "                                           torch_dtype=torch.float32, \n",
    "                                           device_map=torch_device)\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d49385-a7ec-4a70-9338-1f5e7faa082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token=tokenizer.eos_token\n",
    "tokenizer.pad_token_id=tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd9a4b2-f7ef-4432-ba2d-5bd55ee86ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eor_token = 'This is the end of this step' #Use this for trying to get a regex match to terminate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4898f927-7a6e-43c0-aba5-37f9affa6850",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNOWLEDGE TEMPLATE\n",
    "def generic_message_template(textinput: str):\n",
    "    generic_messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": f\"\"\"\n",
    "                You are a helpful chatbot who will always give the correct answer.\n",
    "                \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"{textinput}\"},\n",
    "    ]\n",
    "\n",
    "    return generic_messages\n",
    "\n",
    "def knowledge_message_template(textinput: str):\n",
    "\n",
    "    knowledge_messages = [\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": f\"\"\"\n",
    "                You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
    "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
    "                Make each step the smallest logical unit possible, and make each step 128 words or less.\n",
    "                \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"{textinput}\"},\n",
    "    ]\n",
    "\n",
    "    return knowledge_messages\n",
    "\n",
    "    ### other stuff I tried in the system chat head for knowledge message\n",
    "    \n",
    "        # , and output a {eor_token} at the END of each step of reasoning. Make your outputs for each step incredibly short. If you do not output a {eor_token}, you will be penalized heavily.\n",
    "    \n",
    "        #         Format your logic as follows:\n",
    "    \n",
    "        #         STEP 1: reasoning... {eor_token}\n",
    "        #         STEP 2: reasoning... {eor_token}\n",
    "        #         ...\n",
    "        #         STEP n: reasoning... {eor_token}\n",
    "    \n",
    "        #         \"\"\",\n",
    "    \n",
    "    \n",
    "                # For example, if asked the following:\n",
    "                \n",
    "                # Question:\n",
    "                # 'If there are 10 birds on a branch, and 3 fly away, how many birds are left?'\n",
    "    \n",
    "                # Answer:\n",
    "                # 1. There are 10 birds initially, and 3 fly away, which means we have 10-3 birds left on the branch. {EndOfChain}\n",
    "                # 2. 10 - 3 = 7. {EndOfChain}\n",
    "                # 3. Therefore, there are 7 birds left on the branch. {EndOfChain}\n",
    "\n",
    "def reasoning_message_template(question: str, logic: str):\n",
    "\n",
    "    reasoning_messages = [\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": f\"\"\"\n",
    "               You are a critical chatbot who is supposed to evaluate how strong the reasoning and logic is of a user's input. They will always give you a question and some logic, reasoning, and potentially some maths, and you have to rate it on a scale of 1-100 for how logical it is, with 10 being the most\n",
    "               logical and correct, and 1 being the least. Here are some examples:\n",
    "\n",
    "               ----\n",
    "\n",
    "               USER: Question: If I walked at 5km/h and my destination was 15km away, how long would it take me to walk to my destination and back?\n",
    "\n",
    "               Reasoning: To solve this, I need to know how far I am walking, and the speed of my walk:\n",
    "\n",
    "               Step 1: determine how far I am walking. Distance to destination is 15km, and I am walking back to where I started. Therefore, I am walking 15km there, and 15km back.\n",
    "               Therefore, distance walked is 15km*2 = 30km\n",
    "\n",
    "               Step 2: I know I am walking 5km/h, and I need to walk 30km. 30km divided by 5km/h is 30/5=6.\n",
    "               \n",
    "               Therefore it would take me 6 hours to walk to my destination and back\n",
    "\n",
    "               SYSTEM: There are no logical flaws in its statements, therefore this answer is a 100 out of 100 in reasoning and logic.\n",
    "\n",
    "\n",
    "               ----\n",
    "\n",
    "               USER: Question: if I have 10 apples and I eat 5, how many apples do I have left to eat?\n",
    "\n",
    "               Reasoning: To solve this, I need to know how many apples I started with, and how many I ate, and then subtract the number I ate from the number I started with.\n",
    "\n",
    "               Step 1: I have 10 apples, and I eat 5, then I subtract 5 from 10. 10 - 5 = 7.\n",
    "\n",
    "               Therefore, I have 7 apples left\n",
    "\n",
    "               SYSTEM: Even though the reasoning is correct, the maths is wrong and therefore the answer is wrong. Because of this, this answer is a 40 out of 100. \n",
    "\n",
    "               ----\n",
    "\n",
    "               USER: Question: What is the price of 10 beans, if 20 oranges cost $20, and each bean costs 1/3 of the price of an orange?\n",
    "\n",
    "               Reasoning: To solve this, I need to work out the cost of one bean, and then mulitply by the number of beans.\n",
    "\n",
    "               Step 1: the cost of one bean is $20 * 1/3, because a bean costs 1/3 of the price of an orange. $20 * 1/3 = $6.238176\n",
    "\n",
    "               Step 2: multiply the cost of one bean by 10 to get the cost of 10 beans. $6.238176 * 10 = $523.893284\n",
    "\n",
    "               Therefore the price of 10 beans is $523.893284\n",
    "\n",
    "               SYSTEM: Because there are multiple logical errors and multiple arithmetic errors, this answer is a 1 out of 100. \n",
    "\n",
    "               ---\n",
    "\n",
    "               Now rate the following:\n",
    "\n",
    "                \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Question: {question}\n",
    "            Reasoning: {logic}\n",
    "        \n",
    "        \"\"\"},\n",
    "    ]\n",
    "    return reasoning_messages\n",
    "\n",
    "def tokenize_message(message):\n",
    "    inputs_chattemp = tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(inputs_chattemp, return_tensors='pt').to(torch_device)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f735db-f147-4434-9597-794631d63296",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "question = 'If I ran around a rectangular park twice, where the longer side is 123 metres and the shorter side is 45 metres, how far did I run, and what is the area of the park?'\n",
    "\n",
    "good_logic = \"\"\"\n",
    "To answer these questions, I need to find out the perimeter of the park, and then double it to find out the distance I ran, and then separately I must also multiply the two sides to get the area.\n",
    "\n",
    "Step 1: The longer side of the park is 123 metres, and the shorter side is 45 metres. The perimeter is 2*123m + 2*45m = 336m.\n",
    "\n",
    "Step 2: I ran around the park twice. Twice the perimeter = 2*336m = 672m\n",
    "\n",
    "Therefore I ran 672m.\n",
    "\n",
    "Step 3: To get the area, I must multiply both sides. 123m * 45m = 5535m2\n",
    "\n",
    "Therefore, I ran 672m, and the area of the park is 5535m2\n",
    "\"\"\"\n",
    "\n",
    "bad_logic = \"\"\"\n",
    "To answer these questions, I need to find out the distance ran, and the area.\n",
    "\n",
    "Step 1: The distance ran is twice the perimeter. The perimeter = 123m + 45m = 168m. Therefore the distance ran is 168m * 2 = 302m.\n",
    "\n",
    "Step 2: the area of the park is equal to perimeter^2. Perimeter is 302m^2 = 8172m2.\n",
    "\n",
    "Therefore I ran 302m, and the area of the park is 8172m2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4cf524-8fb2-44f1-ac09-dd9f11bcc917",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "question = 'Yes or no: Would a pear sink in water?'\n",
    "\n",
    "good_logic = \"\"\"\n",
    "The density of a pear is about 0.6 g/cm^3, which is less than water. Thus, a pear would float. Therefore, the answer is no.\n",
    "\"\"\"\n",
    "\n",
    "bad_logic = \"\"\"\n",
    "We do not have enough information to answer the question, but since most pears are not filled with air, the pear would sink. Therefore, the answer is yes.\n",
    "\"\"\"\n",
    "\n",
    "incomplete_logic = \"\"\"\n",
    "To determine if a pear would sink in water, we do not have enough information.\n",
    "\n",
    "Most pears have no air in them\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6b53d0-b92b-4c13-b275-8dbb7f0212a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERIC PIPELINE\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512, do_sample = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f05295-b7c1-4b9d-9368-15c76d1e55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is 0.9 bigger than 0.11?'\n",
    "\n",
    "question = '''\n",
    "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d00f7f8-0bc0-49b5-bf68-5b94a3d7e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a interesting coincidence. However, I need a bit more information to answer your question. You mentioned that the person who painted the famous painting is the same as the name of your favorite cartoon character. Based on the fact that you're in France and looking at one of its most famous art museums, I'm going to take a guess that the painting you're looking at is the Mona Lisa.\n",
      "\n",
      "If that's correct, I believe the cartoon character with the same name is SpongeBob SquarePants.\n"
     ]
    }
   ],
   "source": [
    "# GENERIC QA\n",
    "\n",
    "generic_output = pipe(generic_message_template(question), temperature = 0.1)\n",
    "print(generic_output[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "018ef434-9182-4b86-bb18-1654fe06e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the name of your favorite cartoon character, I'll need to consider the connection between the famous painting and your favorite cartoon character. \n",
      "\n",
      "Step 1: Identify the famous painting in the museum. The painting is likely \"Mona Lisa\" by Leonardo da Vinci, as it is one of the most famous paintings in the Louvre Museum in Paris, France.\n",
      "\n",
      "Step 2: Recall the name of your favorite cartoon character. Since the name of the person who painted the painting is the same as the name of your favorite cartoon character, I'll need to find the name of the person who painted the \"Mona Lisa\".\n",
      "\n",
      "Step 3: Research the name of the person who painted the \"Mona Lisa\". The person who painted the \"Mona Lisa\" is Leonardo da Vinci.\n",
      "\n",
      "Step 4: Determine the name of your favorite cartoon character. Since the name of the person who painted the \"Mona Lisa\" is Leonardo da Vinci, and you mentioned that the name of the person is the same as the name of your favorite cartoon character, I'll need to find the name of a cartoon character with the same name as Leonardo da Vinci.\n",
      "\n",
      "Step 5: Research cartoon characters with the name Leonardo. One popular cartoon character with the name Leonardo is Leonardo from the animated series \"Teenage Mutant Ninja Turtles\". However, this is unlikely to be the correct answer, as the name Leonardo da Vinci is more likely to be associated with a classic cartoon character.\n",
      "\n",
      "Step 6: Research classic cartoon characters with the name Leonardo. One classic cartoon character with the name Leonardo is Leonardo from the animated series \"The Magic Roundabout\". However, this is also unlikely to be the correct answer, as the name Leonardo da Vinci is more likely to be associated with a character from a different franchise.\n",
      "\n",
      "Step 7: Research other classic cartoon characters with the name Leonardo. After researching, I found that the classic cartoon character \"Leonardo\" is actually from the animated series \"The Muppet Show\". However, this is also unlikely to be the correct answer, as the name Leonardo da Vinci is more likely to be associated with a character from a different franchise.\n",
      "\n",
      "Step 8: Research the name of the classic cartoon character \"Leonardo\". After researching, I found that the classic cartoon character \"Leonardo\" is actually from the animated series \"The Adventures of Pinocchio\". However, this is also unlikely to be the correct answer, as the name Leonardo da Vinci is more likely to be associated with a character from a different franchise.\n",
      "\n",
      "Step 9\n"
     ]
    }
   ],
   "source": [
    "# CHAIN OF THOUGHT QA\n",
    "\n",
    "CoT_output = pipe(knowledge_message_template(question), temperature = 0.1)\n",
    "print(CoT_output[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b66b304-3ad0-49bb-b09b-f5d2353c9f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating branches for iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:20<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating logic of 5 branches for iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:50<00:00, 10.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating branches for iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:22<00:00,  4.49s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:24<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating logic of 10 branches for iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [02:30<00:00, 15.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating branches for iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.75s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:21<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating logic of 10 branches for iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████▌        | 9/10 [02:14<00:14, 14.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating branches for iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.92s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating logic of 10 branches for iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▌                                        | 5/10 [00:00<00:00, 45689.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping generation and iteration because we have more than 2 final outputs - we have 6 complete solutions to examine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:33<00:00, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
      "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
      "                Make each step the smallest logical unit possible, and make each step 128 words or less.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To solve this problem, I'll break it down into smaller steps.\n",
      "\n",
      "Step 1: Identify the famous painting in the museum.\n",
      "The painting I'm assuming you're looking at is the Mona Lisa by Leonardo da Vinci.\n",
      "\n",
      "Step 2: Identify the artist of the painting.\n",
      "The artist of the Mona Lisa is Leonardo da Vinci.\n",
      "\n",
      "Step 3: Determine the name of the cartoon character.\n",
      "Since the name of the artist is the same as the name of your favorite cartoon character, I'll need to find the name of the cartoon character associated with Leonardo da Vinci.\n",
      "\n",
      "Step 4: Recall or research the name of the cartoon character.\n",
      "Leonardo da Vinci is often associated with the cartoon character Leonardo, but I'll need to consider other possibilities. A more likely candidate is the cartoon character from the popular animated series \"The Simpsons.\"<|eot_id|>\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~\n",
      "Time spent thinking: 0:01:51.329746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MTCS chain of thought using only strict token limits\n",
    "num_branches = 5\n",
    "\n",
    "num_candidates = 2\n",
    "\n",
    "max_iters = 6\n",
    "\n",
    "current_iter = 0\n",
    "\n",
    "final_branches = []\n",
    "\n",
    "running_outputs = []\n",
    "\n",
    "# Conditions to stop generating: if minimum number of final candidates met, if max iters hit, \n",
    "generating = True\n",
    "\n",
    "while generating:\n",
    "    starttime = datetime.now()\n",
    "    \n",
    "    if current_iter == 0:\n",
    "        inputs_cot = [tokenize_message(knowledge_message_template(question))]\n",
    "        branches_list=[]\n",
    "    else:\n",
    "        inputs_cot = [tokenizer(branch, return_tensors='pt').to(torch_device) for branch in branches_list]\n",
    "\n",
    "    #save interim text outputs:\n",
    "    running_outputs.append(branches_list)\n",
    "\n",
    "    #re-init all interim variables\n",
    "    branches_list = []\n",
    "\n",
    "    logic_scores = []\n",
    "\n",
    "\n",
    "    # generate initial number of branches\n",
    "    print(f\"generating branches for iteration {current_iter}\")\n",
    "    for candidate in inputs_cot:\n",
    "        for i in tqdm(range(num_branches)):\n",
    "            branchoutput = model.generate(**candidate, max_new_tokens=64, temperature=0.1).cpu()\n",
    "            output_text = tokenizer.batch_decode(branchoutput)[0]\n",
    "            branches_list.append(output_text)\n",
    "    print(f\"evaluating logic of {len(branches_list)} branches for iteration {current_iter}\")\n",
    "    #evaluate logic\n",
    "    for output in tqdm(branches_list):\n",
    "        #clean outputs\n",
    "        chat_list = output.split('<|eot_id|>')\n",
    "        # ADD LOGIC HERE TO GET GENERATION TO STOP AFTER THERE'S TWO \n",
    "    \n",
    "        # MAKE THE LOGIC THAT WE MUST HIT MINIMUM NUMBER OF NUM_CANDIDATES BEFORE STOPPING GENERATING\n",
    "        if len(chat_list) > 3:\n",
    "            final_branches.append(output)\n",
    "            branches_list.remove(output)\n",
    "            continue\n",
    "        \n",
    "        # isolating the output logic\n",
    "        logic = chat_list[2].replace(\"<|start_header_id|>assistant<|end_header_id|>\\n\", \"\")\n",
    "        results = pipe(reasoning_message_template(question, logic), temperature = 0.1)\n",
    "        results_text = results[-1]['generated_text'][-1]['content']\n",
    "        #jank error handling for weird generations\n",
    "        try:\n",
    "            results_score = int(re.search('([\\d]+)(?=\\s+out of 10)', results_text).group(0))\n",
    "        except:\n",
    "            print(f\"no valid string match for {output} results - the output was: \\n {results_text}\")\n",
    "            results_score = 0\n",
    "            # NOTE: this is potentially getting rid of valid and good responses, but I'm being super lazy to get an MVP loop working\n",
    "            continue\n",
    "    \n",
    "        logic_scores.append(results_score)\n",
    "\n",
    "    \n",
    "    # if we reach the\n",
    "    if len(final_branches) > num_candidates:\n",
    "        generating = False\n",
    "        print(f\"stopping generation and iteration because we have more than {num_candidates} final outputs - we have {len(final_branches)} complete solutions to examine\")\n",
    "        final_branch_scores = []\n",
    "        for solution in tqdm(final_branches):\n",
    "            chat_list = output.split('<|eot_id|>')\n",
    "            logic = chat_list[2].replace(\"<|start_header_id|>assistant<|end_header_id|>\\n\", \"\")\n",
    "            results = pipe(reasoning_message_template(question, logic), temperature = 0.1)\n",
    "            results_text = results[-1]['generated_text'][-1]['content']\n",
    "            try:\n",
    "                results_score = int(re.search('([\\d]+)(?=\\s+out of 10)', results_text).group(0))\n",
    "            except:\n",
    "                print(f\"no valid string match for {output} results - the output was: \\n {results_text}\")\n",
    "                results_score = 0\n",
    "                # NOTE: this is potentially getting rid of valid and good responses, but I'm being super lazy to get an MVP loop working\n",
    "                continue\n",
    "            final_branch_scores.append(results_score)\n",
    "\n",
    "        selection = np.argmax(final_branch_scores)\n",
    "\n",
    "        final_output = final_branches[selection]\n",
    "        print(final_output)\n",
    "        print(\"~*~*~*~*~*~*~*~*~*~*~*~*~\")\n",
    "        print(f\"Time spent thinking: {datetime.now()-starttime}\")\n",
    "\n",
    "    elif current_iter >= max_iters:\n",
    "        generating = False\n",
    "        print(f\"stopping generation and iteration - we have exceeded {max_iters} iterations. We have {len(final_branches)} complete solutions and {len(branches_list)} dangling branches to examine.\")\n",
    "        final_branches = final_branches.extend(branches_list)\n",
    "        final_branch_scores = []\n",
    "        for solution in tqdm(final_branches):\n",
    "            chat_list = output.split('<|eot_id|>')\n",
    "            logic = chat_list[2].replace(\"<|start_header_id|>assistant<|end_header_id|>\\n\", \"\")\n",
    "            results = pipe(reasoning_message_template(question, logic), temperature = 0.1)\n",
    "            results_text = results[-1]['generated_text'][-1]['content']\n",
    "            try:\n",
    "                results_score = int(re.search('([\\d]+)(?=\\s+out of 10)', results_text).group(0))\n",
    "            except:\n",
    "                print(f\"no valid string match for {output} results - the output was: \\n {results_text}\")\n",
    "                results_score = 0\n",
    "                # NOTE: this is potentially getting rid of valid and good responses, but I'm being super lazy to get an MVP loop working\n",
    "                continue\n",
    "            final_branch_scores.append(results_score)\n",
    "\n",
    "        selection = np.argmax(final_branch_scores)\n",
    "\n",
    "        final_output = final_branches[selection]\n",
    "        print(final_output)\n",
    "        print(\"~*~*~*~*~*~*~*~*~*~*~*~*~\")\n",
    "        print(f\"Time spent thinking: {datetime.now()-starttime}\")\n",
    "    \n",
    "    else:\n",
    "        probs = softmax(logic_scores).tolist()\n",
    "        chosen_keys = np.random.choice(len(probs), size=num_candidates, replace = False, p = probs).tolist()\n",
    "        branches_list = [branches_list[index] for index in chosen_keys]\n",
    "        current_iter +=1\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "625eee63-9134-43f5-9d42-bcb2801e7d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 60, 60, 60, 60, 60]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_branch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c000add-9224-49a8-bdb2-0363c6fbeaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
      "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
      "                Make each step the smallest logical unit possible, and make each step 128 words or less.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To solve this problem, I'll break it down into smaller steps.\n",
      "\n",
      "Step 1: Identify the famous painting in the museum.\n",
      "The painting I'm assuming you're looking at is the Mona Lisa by Leonardo da Vinci.\n",
      "\n",
      "Step 2: Identify the artist of the painting.\n",
      "The artist of the Mona Lisa is Leonardo da Vinci.\n",
      "\n",
      "Step 3: Determine the name of the cartoon character.\n",
      "Since the name of the artist is the same as the name of your favorite cartoon character, I'll need to find the name of the cartoon character associated with Leonardo da Vinci.\n",
      "\n",
      "Step 4: Recall or research the name of the cartoon character.\n",
      "Leonardo da Vinci is often associated with the cartoon character Leonardo, but I'll need to consider other possibilities. A more likely candidate is the cartoon character from the popular animated series \"The Simpsons.\"<|eot_id|>\n",
      "~~~~~~~~~\n",
      "<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
      "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
      "                Make each step the smallest logical unit possible, and make each step 128 words or less.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To determine the name of your favorite cartoon, I'll need to follow a logical chain of steps.\n",
      "\n",
      "First, I need to identify the most famous painting in the museum you're in. Based on the fact that you're in France, I'm going to take a guess that the painting you're looking at is the \"Mona Lisa\" by Leonardo da Vinci.\n",
      "\n",
      "Next, I need to verify if the Mona Lisa is indeed the painting you're looking at. To do this, I'll consider the fact that the Mona Lisa is one of the most famous paintings in the Louvre Museum in Paris, France. If you're in the Louvre Museum, it's likely that the painting you're looking at is the Mona Lisa.\n",
      "\n",
      "Now, I need to identify the artist of the Mona Lisa. I know that the Mona Lisa was painted by Leonardo da Vinci. \n",
      "\n",
      "Now, I need to consider the name of the cartoon character that shares the same name as the artist. I'm going to take a guess that the cartoon character is SpongeBob SquarePants.<|eot_id|>\n",
      "~~~~~~~~~\n",
      "<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
      "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
      "                Make each step the smallest logical unit possible, and make each step 128 words or less.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To determine the name of your favorite cartoon, I'll need to follow a logical chain of steps.\n",
      "\n",
      "First, I need to identify the most famous painting in the museum you're in. Based on the fact that you're in France, I'm going to take a guess that the painting you're looking at is the \"Mona Lisa\" by Leonardo da Vinci.\n",
      "\n",
      "Next, I need to verify if the Mona Lisa is indeed the painting you're looking at. To do this, I'll consider the fact that the Mona Lisa is one of the most famous paintings in the Louvre Museum in Paris, France. If you're in the Louvre Museum, it's likely that the painting you're looking at is the Mona Lisa.\n",
      "\n",
      "Now, I need to identify the artist of the Mona Lisa. I know that the Mona Lisa was painted by Leonardo da Vinci. \n",
      "\n",
      "Now, I need to consider the name of the cartoon character that shares the same name as the artist. I'm going to take a guess that the cartoon character you're thinking of is Leonardo.<|eot_id|>\n",
      "~~~~~~~~~\n",
      "<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
      "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
      "                Make each step the smallest logical unit possible, and make each step 128 words or less.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To determine the name of your favorite cartoon, I'll need to follow a logical chain of steps.\n",
      "\n",
      "First, I need to identify the most famous painting in the museum you're in. Based on the fact that you're in France, I'm going to take a guess that the painting you're looking at is the \"Mona Lisa\" by Leonardo da Vinci.\n",
      "\n",
      "Next, I need to verify if the Mona Lisa is indeed the painting you're looking at. To do this, I'll consider the fact that the Mona Lisa is one of the most famous paintings in the Louvre Museum in Paris, France. If you're in the Louvre Museum, it's likely that the painting you're looking at is the Mona Lisa.\n",
      "\n",
      "Now, I need to identify the artist of the Mona Lisa. I know that the Mona Lisa was painted by Leonardo da Vinci. \n",
      "\n",
      "Now, I need to consider the name of the cartoon character that shares the same name as the artist. I'm going to take a guess that the cartoon character is SpongeBob SquarePants.<|eot_id|>\n",
      "~~~~~~~~~\n",
      "<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
      "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
      "                Make each step the smallest logical unit possible, and make each step 128 words or less.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To solve this problem, I'll break it down into smaller steps.\n",
      "\n",
      "Step 1: Identify the famous painting in the museum.\n",
      "The painting I'm assuming you're looking at is the Mona Lisa by Leonardo da Vinci.\n",
      "\n",
      "Step 2: Identify the artist of the painting.\n",
      "The artist of the Mona Lisa is Leonardo da Vinci.\n",
      "\n",
      "Step 3: Determine the name of the cartoon character.\n",
      "Since the name of the artist is the same as the name of your favorite cartoon character, I'll need to find the name of the cartoon character associated with Leonardo da Vinci.\n",
      "\n",
      "Step 4: Recall or research the name of the cartoon character.\n",
      "Leonardo da Vinci is often associated with the cartoon character Leonardo, but I'm assuming you're thinking of a more common cartoon character. A popular cartoon character with the name Leonardo is Leonardo from the animated TV show \"The Simpsons\".\n",
      "\n",
      "Step 5: Confirm the name of the cartoon character.\n",
      "Based on the information, I'm going to take a guess that your favorite cartoon character is Leonardo from \"The Simpsons\".<|eot_id|>\n",
      "~~~~~~~~~\n",
      "<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful chatbot who will always give the correct answer, and use chain of thought reasoning to think step by step through complicated problems. \n",
      "                Consider what information you would need to find, what operations you would need to solve the problem, and give reasoning for each step. \n",
      "                Make each step the smallest logical unit possible, and make each step 128 words or less.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am in France, in one of its most famous art museums. I am looking at its most famous painting. The name of the person who painted this picture is the same as the name of my favourite cartoon character growing up. What is the name of my favourite cartoon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To solve this problem, I'll break it down into smaller steps.\n",
      "\n",
      "Step 1: Identify the famous painting in the museum.\n",
      "The painting I'm assuming you're looking at is the Mona Lisa by Leonardo da Vinci.\n",
      "\n",
      "Step 2: Identify the artist of the painting.\n",
      "The artist of the Mona Lisa is Leonardo da Vinci.\n",
      "\n",
      "Step 3: Determine the name of the cartoon character.\n",
      "Since the name of the artist is the same as the name of your favorite cartoon character, I'll need to find the name of the cartoon character associated with Leonardo da Vinci.\n",
      "\n",
      "Step 4: Recall or research the name of the cartoon character.\n",
      "Leonardo da Vinci is often associated with the cartoon character Leonardo, but I'm assuming you're thinking of a more common cartoon character. A popular cartoon character with the name Leonardo is Leonardo from the animated TV show \"The Simpsons\".\n",
      "\n",
      "Step 5: Confirm the name of the cartoon character.\n",
      "Based on the information, I'm going to take a guess that your favorite cartoon character is Leonardo from \"The Simpsons\".<|eot_id|>\n",
      "~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for i in final_branches:\n",
    "    print(i)\n",
    "    print('~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878a8c3-6ed1-4900-a307-159fd9ee929a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RF-demos",
   "language": "python",
   "name": "rf-demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
